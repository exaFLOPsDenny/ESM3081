{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_breast_cancer, load_digits, load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_validate\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Supervised_Learning_1_Basics\n",
    "# 1. Supervised_Learning_2_k_Nearest_Neighbors\n",
    "# 1. Supervised_Learning_3_Linear_Models\n",
    "# 1. Supervised_Learning_4_Decision_Trees_Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Supervised_Learning_5_Support_Vector_Machines\n",
    "\n",
    "########## SVR\n",
    "\n",
    "X, y = mglearn.datasets.load_extended_boston()]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scalerX = StandardScaler()\n",
    "scalerX.fit(X_train)\n",
    "X_train_scaled = scalerX.transform(X_train)\n",
    "X_test_scaled = scalerX.transform(X_test) # Same scaling for the test datset (Exploring the test dataset is prohibited.)\n",
    "\n",
    "# Slack variable in SVR are effected by the target value. Ergo, the target needs to be also scaled.\n",
    "# (Prof. 강석호) 회귀 문제를 위한 예측모델 학습 시(예를 들어, Decision Tree와 k-NN은 target label의 scaling에 invariant하여 제외) target label의 scaling이 권장됩니다.\n",
    "\n",
    "scalerY = StandardScaler()\n",
    "scalerY.fit(y_train.reshape(-1,1))\n",
    "y_train_scaled = scalerY.transform(y_train.reshape(-1,1))\n",
    "y_test_scaled = scalerY.transform(y_test.reshape(-1,1))\n",
    "\n",
    "reg = SVR()\n",
    "reg.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# For Evaluation, target value should be inverse transformed.\n",
    "y_train_hat_scaled = reg.predict(X_train_scaled)\n",
    "y_train_hat = scalerY.inverse_transform(y_train_hat_scaled.reshape(-1,1))\n",
    "\n",
    "print(mean_absolute_error(y_train, y_train_hat))\n",
    "print(mean_squared_error(y_train, y_train_hat) ** 0.5) # Root for RMSE\n",
    "print(r2_score(y_train, y_train_hat))\n",
    "\n",
    "\n",
    "y_test_hat_scaled = reg.predict(X_test_scaled)\n",
    "y_test_hat = scalerY.inverse_transform(y_test_hat_scaled.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Supervised_Learning_6_Neural_Networks\n",
    "\n",
    "# Like SVR MLPRegressor needs to scale y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Unsupervised_Learning_1_Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Unsupervised_Learning_2_PCA\n",
    "\n",
    "########## PCA in supervised learning(w\\ KNN)\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state= 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=2) # without n_components no dimension reduction is occured\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors= 3)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "y_train_hat = clf.predict(X_train_pca)\n",
    "y_test_hat = clf.predict(X_test_pca)\n",
    "\n",
    "# PCA have inverse transformation so it can get new data and evaluate it\n",
    "X_test_rec = pca.inverse_transform(X_test_pca) # 여기서 X_test_scaled 아니야!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Unsupervised_Learning_3_tSNE\n",
    "\n",
    "# Unlike PCA, t-SNE does not support transforming new(test) data\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "tsne = TSNE(random_state=42)\n",
    "digits_tsne = tsne.fit_transform(digits.data) # use fit_transform instead of fit, as t-SNE has no transform method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Unsupervised_Learning_4_kMeans_HC (중요도 낮음)\n",
    "\n",
    "# K-means는 새로운 데이터 접근가능!\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, y_train = iris.data, iris.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_scaled) # 새로운 데이터에 하려면 fit만\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X_train_scaled)\n",
    "\n",
    "print(scaler.inverse_transform(kmeans.cluster_centers_))\n",
    "\n",
    "assignments_X_train_scaled = kmeans.labels_\n",
    "\n",
    "assignments_X_new = kmeans.predict(X_new)\n",
    "\n",
    "\n",
    "# Hierarchical CLustering의 대표적인 Agglomerative Clustering은 새로운 데이터 접근 불가능! (no predict method)\n",
    "agg = AgglomerativeClustering(n_clusters=3, linkage= \"ward\")\n",
    "agg.fit(X_train)\n",
    "\n",
    "assignments_X_train = agg.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Unsupervised_Learning_5_DBC\n",
    "scaler = MinMaxScaler((-1,1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "dbscan = DBSCAN()\n",
    "dbscan.fit(X_train_scaled)\n",
    "\n",
    "assignments_X_train_scaled = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Representing_Data_and_Engineering_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model_Evaluation_and_Improvement (여기부터 가장 중요!)\n",
    "\n",
    "# Stratified k-Fold Cross-Validation with data scaling\n",
    "iris = load_iris()\n",
    "scaler = StandardScaler()\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle= True, random_state=1) # random state fixed\n",
    "\n",
    "score_train = []\n",
    "score_test = []\n",
    "\n",
    "for train_idx, test_idx in kfold.split(iris.data, iris.target):\n",
    "    X_train = iris.data[train_idx]\n",
    "    y_train = iris.target[train_idx]\n",
    "    X_test = iris.data[test_idx]\n",
    "    y_test = iris.data[test_idx]\n",
    "    \n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    clf = MLPClassifier(max_iter= 1000, random_state= 0)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_train_hat = clf.predict(X_train_scaled)\n",
    "    y_test_hat = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search with validation set\n",
    "\n",
    "iris = load_iris()\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(iris.data, iris.target, test_size= 0.25, random_state=0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, test_size= 0.25, random_state=1) # 여기서 iris.data 아니라 위에서 분리한 train+val dataset!!\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) # 처음엔 hyperparameter 설정을 위해 validation과 비교할 것이기에 scale은 X_train!!\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid) # Valid가 여기서 test data 같은 느낌이기에 X_valid또한 X_train scaler로 scaling!\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 1, 10, 100]:\n",
    "        clf = SVC(gamma = gamma, C = C)\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_valid_hat = clf.predict(X_valid_scaled) # 여기에 X_test 집어넣으면 안돼!!\n",
    "        score = accuracy_score(y_valid, y_valid_hat)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_hyperparameters = {'C': C, \"gamma\": gamma}\n",
    "            \n",
    "scaler.fit(X_trainval) # 이젠 validation 역할 다했어! train으로 merge\n",
    "X_train_scaled = scaler.transform(X_trainval)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = SVC(**best_best_hyperparameters)\n",
    "clf.fit(X_trainval, y_trainval)\n",
    "\n",
    "y_test_hat = clf.predict(X_test_scaled)\n",
    "test_score = accuracy_score(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search with Cross-Validation(with data scaling without pipelines) Wrong way to do\n",
    "\n",
    "iris = load_iris()\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(iris.data, iris.target, test_size= 0.25, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_trainval) # 사실 train만 해야하는데...\n",
    "X_trainval_scaled = scaler.transform(X_trainval)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits= 5, shuffle= True, random_state= 2)\n",
    "hyperparam_grid = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV( SVC(), hyperparam_grid, scoring= \"accuracy\", refit=True, cv=kfold)\n",
    "grid_search.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested Cross-Validation\n",
    "\n",
    "iris = load_iris()\n",
    "hyperparam_grid = [{\"kernel\":[\"rbf\"], \n",
    "                    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                    \"gamma\": [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "                   {\"kernel\": [\"linear\"],\n",
    "                    \"C\":[0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "inner_kfold = StratifiedKFold(n_splits= 5, shuffle= True, random_state=2)\n",
    "outer_kfold = StratifiedKFold(n_splits= 5, shuffle= True, random_state=2)\n",
    "grid_search = GridSearchCV(SVC(), hyperparam_grid, scoring= \"accuracy\", refit= True, cv= inner_kfold) # inner_kfold\n",
    "scores = cross_validate(grid_search, iris.data, iris.target, scoring= \"accuracy\", cv=outer_kfold, return_estimator= True, return_train_score= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested Cross-validation with data scaling (위 문제 해결 x 하려면 gridsearchcv 사용 x)\n",
    "iris = load_iris()\n",
    "hyperparam_grid = [{\"kernel\":[\"rbf\"], \n",
    "                    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                    \"gamma\": [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "                   {\"kernel\": [\"linear\"],\n",
    "                    \"C\":[0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "inner_kfold = StratifiedKFold(n_splits= 5, shuffle= True, random_state=2)\n",
    "outer_kfold = StratifiedKFold(n_splits= 5, shuffle= True, random_state=2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "score_test = []\n",
    "\n",
    "for trainval_idx, test_idx in outer_kfold.split(iris.data, iris.target):\n",
    "    X_trainval = iris.data[trainval_idx]\n",
    "    y_trainval = iris.target[trainval_idx]\n",
    "    \n",
    "    X_test = iris.data[test_idx]\n",
    "    y_test = iris.target[test_idx]\n",
    "    \n",
    "    scaler.fit(X_trainval)\n",
    "    X_trainval_scaled = scaler.transform[X_trainval]\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    grid_search = GridSearchCV(SVC(), hyperparam_grid, scoring= \"accuracy\", refit= True, cv =inner_kfold)\n",
    "    grid_search.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    y_test_hat = grid_search.predict(X_test_scaled)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search with Cross-Validation(with data scaling using pipelines)\n",
    "iris =load_iris()\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(iris.data, iris.target, test_size= 0.25, random_state=0)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"svm\", SVC())])\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle= True, random_state=2)\n",
    "hyperparam_grid = {\"svm__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                   \"svm_gamma\": [0.001, 0.01, 0.1, 1, 10, 100]} # step name + __ (double) + hyperparameter name\n",
    "grid_search = GridSearchCV(pipe, hyperparam_grid, scoring=\"accuracy\", refit= True, cv=kfold)\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "\n",
    "format(grid_search.best_score_, grid_search.best_params_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
